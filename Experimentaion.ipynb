{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_dim)  # Combine center and context\n",
    "\n",
    "    def forward(self, center, context):\n",
    "        center_emb = self.embeddings(center)\n",
    "        output = torch.matmul(center_emb, self.embeddings(context).transpose(0, 1))\n",
    "        return output\n",
    "\n",
    "    def get_similarity(self, idx):\n",
    "        with torch.no_grad():\n",
    "            center_emb = self.embeddings.weight[idx]\n",
    "            similarities = torch.cosine_similarity(\n",
    "                center_emb.unsqueeze(0), self.embeddings.weight, dim=1\n",
    "            )\n",
    "        return similarities\n",
    "\n",
    "    def get_cosine_distance(self, idx):\n",
    "        similarities = self.get_similarity(idx)\n",
    "        return 1 - similarities\n",
    "\n",
    "\n",
    "class CorpusData(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        center, context = self.data[idx]\n",
    "        return center, context\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class Corpus:\n",
    "    def __init__(self, file_name, window_size=1):\n",
    "        self.file_name = file_name\n",
    "        self.window_size = window_size\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.vocab_size = 0\n",
    "        self.data = []\n",
    "        self.__build_data()\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.file_name, \"r\") as file:\n",
    "            yield from file\n",
    "\n",
    "    def __update_map(self, text):\n",
    "        for word in text:\n",
    "            if word not in self.word2id:\n",
    "                self.word2id[word] = self.vocab_size\n",
    "                self.id2word[self.vocab_size] = word\n",
    "                self.vocab_size += 1\n",
    "\n",
    "    def __write_pairs(self, text):\n",
    "        num_words = len(text)\n",
    "        for i, word in enumerate(text):\n",
    "            center = self.word2id[word]\n",
    "            for context_word in (\n",
    "                text[max(0, i - self.window_size) : i]\n",
    "                + text[i + 1 : min(num_words, i + self.window_size + 1)]\n",
    "            ):\n",
    "                context_id = self.word2id[context_word]\n",
    "                self.data.append((center, context_id))\n",
    "\n",
    "    def __build_data(self):\n",
    "        for line in self:\n",
    "            text = line.strip().split()\n",
    "            text = [word.strip() for word in text if len(word) > 2]\n",
    "            self.__update_map(text)\n",
    "            self.__write_pairs(text)\n",
    "        self.data = list(set(self.data))  # Remove duplicates\n",
    "\n",
    "    def get_pairs(self):\n",
    "        return CorpusData(self.data)\n",
    "\n",
    "\n",
    "def train(model, dataloader, num_epochs, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    log = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1}\")\n",
    "        for center, context in pbar:\n",
    "            output = model(center.to(device), context.to(device))\n",
    "            loss = criterion(output, torch.zeros_like(output).to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * center.size(0)\n",
    "            pbar.set_postfix(loss=f\"{total_loss / len(dataloader.dataset):.2f}\")\n",
    "        log.append(total_loss / len(dataloader.dataset))\n",
    "    model.eval()\n",
    "    return model, log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"data/\"\n",
    "TRAIN_NORM = f\"{DATA}/train_norm.txt\"\n",
    "TEST_NORM = f\"{DATA}/test_norm.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(TRAIN_NORM, 3)\n",
    "corpus_train = CorpusData(corpus.data)\n",
    "corpus_loader = DataLoader(corpus_train, batch_size=4096, shuffle=True)\n",
    "N = corpus.vocab_size\n",
    "H = 25\n",
    "model = SkipGram(N, H)\n",
    "device = \"mps\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1251/1251 [00:37<00:00, 33.04it/s, loss=0.00]\n",
      "Epoch 2:   7%|▋         | 84/1251 [00:02<00:29, 40.02it/s, loss=0.00]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x10354d3c0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lucien/.pyenv/versions/3.10.14/envs/torch/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Epoch 2:  39%|███▊      | 484/1251 [00:15<00:28, 27.38it/s, loss=0.00]"
     ]
    }
   ],
   "source": [
    "model, log = train(model, corpus_loader, 10,criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
